# =============================================================================
# rag-tag environment configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.sample .env
#
# The app loads .env automatically via python-dotenv -- no need to export
# variables or pass them on the command line.
# =============================================================================

# ---------------------------------------------------------------------------
# LLM API Keys (set at least one)
# ---------------------------------------------------------------------------
COHERE_API_KEY=
GEMINI_API_KEY=
OPENAI_API_KEY=

# ---------------------------------------------------------------------------
# Provider selection (optional)
# ---------------------------------------------------------------------------
# LLM_PROVIDER sets the default for both router and agent.
# AGENT_PROVIDER / ROUTER_PROVIDER override individually.
# Valid values: cohere, gemini, openai
# If unset, auto-detected from whichever API key is present.
# LLM_PROVIDER=gemini
# AGENT_PROVIDER=cohere
# ROUTER_PROVIDER=gemini

# ---------------------------------------------------------------------------
# Model selection (optional)
# ---------------------------------------------------------------------------
# Per-provider model names.
# Defaults by purpose:
# - Router defaults: Cohere=command-r-08-2024, Gemini=gemini-2.5-flash, OpenAI=gpt-4o
# - Agent defaults:  Cohere=command-a-03-2025, Gemini=gemini-2.5-flash, OpenAI=gpt-4o
# COHERE_MODEL=command-a-03-2025
# GEMINI_MODEL=gemini-2.5-flash
# OPENAI_MODEL=gpt-4o
# AGENT_MODEL=                           # overrides the agent model regardless of provider
# ROUTER_MODEL=                          # overrides the router model regardless of provider

# ---------------------------------------------------------------------------
# Router mode (optional)
# ---------------------------------------------------------------------------
# rule  = regex-based routing (no LLM call, fast, no API key needed for routing)
# llm   = LLM classifies the question (falls back to rules on failure)
# unset = auto-detect (uses LLM if an API key is available, otherwise rules)
# ROUTER_MODE=rule

# ---------------------------------------------------------------------------
# Observability (optional)
# ---------------------------------------------------------------------------
# Set a Logfire token to send traces to Logfire cloud.
# If omitted, --trace runs in local-only mode.
# LOGFIRE_TOKEN=

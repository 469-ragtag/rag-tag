# LLM providers
# Set at least one of these API keys.
COHERE_API_KEY=your_cohere_api_key
GEMINI_API_KEY=your_gemini_api_key

# Note: COHERE_API_KEY is automatically mapped to CO_API_KEY for PydanticAI compatibility

# Model selection (PydanticAI format: provider:model-name)
# - ROUTER_MODEL: Model for query routing (default: google-gla:gemini-2.5-flash)
# - AGENT_MODEL: Model for graph agent (default: cohere:command-a-03-2025)
# Note: Use 'google-gla' for AI Studio or 'google-vertex' for Vertex AI (not 'google')
ROUTER_MODEL=google-gla:gemini-2.5-flash
AGENT_MODEL=cohere:command-a-03-2025

# Router mode: rule | llm (optional; defaults to llm if any provider key is set)
ROUTER_MODE=llm
LOGFIRE_TOKEN=your-read-logfire-token

# Legacy provider/model vars (DEPRECATED - use ROUTER_MODEL/AGENT_MODEL instead)
# These are kept for backward compatibility but will be removed in a future version.
# LLM_PROVIDER=gemini
# ROUTER_PROVIDER=gemini
# AGENT_PROVIDER=cohere
# GEMINI_MODEL=gemini-2.5-flash
# COHERE_MODEL=command-a-03-2025
